# ECNU-DistSys-Final-2024
**大规模数据处理系统 - 期末小组作业**

主题: **对Spark可扩展性的实验探究**

## 实验设计
### 实验负载
随机森林训练，约 500k 行，CPU密集型任务。
负载以 Client 模式运行在 Spark Master 容器中。

### 采集数据
1. 通过 cAdvisor + Prometheus + Grafana 监控 docker 的各项资源占用，主要监控网络占用，可以自动绘制图表。
2. 实验代码中最后输出总训练时长; Spark UI 中也可以看到。手动导入数据用 python 脚本绘制折线图。

### 1. 固定 worker 配置，调整 worker 的数量

#### 参数
将每个 worker 配置成 1 核心, 1 GB 内存。

并行度倍率：总核数的 3 倍(spark.default.parallelism = 3 × 核数)。 

分别测试 1, 2, 4, 8, 16 个 worker 下的表现。

#### 预期结果与可能结论
理想情况下，每一份 worker 都能把自身资源完整利用上，执行速度随 worker 数量线性增长，则执行时间随 worker 数量的增长反比例下降。但考虑到调度开销、任务启动开销等由 Spark 框架带来的不可避免的开销，实际情况肯定不会这么完美，只能是接近，执行时间会比预期要长一些。

由于我们使用 CPU 密集型的任务进行测试，由于 Spark 的设计，我们应能得到"执行时间随 worker 数量的增加而近似反比例降低" 的结果，能够体现 Spark 对于横向扩展的良好支持。但是大量的 worker 也会带来大量的网络流量，可能会成为瓶颈。

### 2. 固定资源池，在相同负载下逐渐增加 worker 数量

#### 参数
总资源池配置成 16 核心 32 GB 内存。

并行度倍率：总核数的 3 倍(spark.default.parallelism = 3 × 核数), 此处即固定为 48 并行度。 

| worker 数量 | 每 worker 核心数 | 每 worker 内存数 |
|:-|-|-|
| 1  | 16 | 32 |
| 2  | 8  | 16 |
| 4  | 4  | 8  |
| 8  | 2  | 4  |
| 16 | 1  | 2  |

#### 预期结果与可能结论
虽然总的核心和内存数量不变，但是考虑到 Spark 的调度开销，执行时间应会随着 worker 数量的增加而增加，但并不明显，应能表明 Spark 的设计比较优良。

这次实验中也包含了一个单机 16 核心 32GB 内存的情况，执行时间很短，也能表明 Spark 对纵向扩展的支持非常好。

### 3. 固定 worker 数量，调整数据集大小

#### 参数
使用 16 个 1 核心 1GB 内存的 worker。

测试 3 种数据集，行数分别为 5k 行, 50k 行, 500k 行。

并行度倍率：总核数的 3 倍(spark.default.parallelism = 3 × 核数), 此处即固定为 48 并行度。 

#### 预期结果与可能结论

理想情况中，随着数据集的明显增大，训练时间也应明显增大。但是由于我们的数据量比较小，实际上可能算不上 CPU 密集型的任务，反而成为 IO 密集型。实际的训练时间变长的幅度远达不到数据集这种10倍的增长幅度。在数据集过小的情况下，各个 worker 的利用率应该都比较低，任务常被 Master 拖累。

应能说明 worker 数量要与实际负载匹配，将小负载分散到大量 worker 中并不能带来可观的时间减小。


## PPT 大纲
1. 基本信息 (~1min)
    + 组员
    + 标题(研究目的)
    + 大概做了什么
2. 实验环境+研究方法 (~2.5 min)
    + Docker, 通过修改配置文件模拟多机; 通过绑核限制资源上限。
    + Prometheus + Grafana 监控网络、磁盘、CPU
    + Spark 管理界面中可以观察执行时间
    + 负载：随机森林，预测碳排放量; 数据预处理
3. 实验一: 固定 worker 配置，调整 worker 的数量 (~1min)
    + 折线图，表明 Spark 的可扩展性虽不及理想，但也非常优秀 (scale out)
4. 实验二: 固定资源池，在相同负载下逐渐增加 worker 数量 (~1min)
    + 柱状图，表明 worker 数量增大会带来显著的调度、网络开销
    + 并行度合适的情况下，Spark 能够智能地利用当前机器上的所有资源进行计算 (scale up)
5. 实验三: 固定 worker 数量，调整数据集大小 (~1min)
    + 柱状图，表明 worker 数量要与实际负载匹配，将小负载分散到大量 worker 中并不能带来可观的时间减小。

## 分工 
+ 吴清源: 实验设计、结果分析、文档撰写
+ 周凯文: 编写pyspark代码、数据处理、数据可视化、实验结果可视化
+ 杨柳：实验设计、镜像构建、`服务器、集群及性能监测`环境的部署和测试、数据可视化、数据收集、部署文档撰写
+ 董宸廷：实验设计、实验结果收集、PPT制作
